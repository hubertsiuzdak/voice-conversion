{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voice Conversion",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hubertsiuzdak/voice-conversion/blob/master/demo/Voice_Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JPXvJfPLPzy",
        "colab_type": "text"
      },
      "source": [
        "## Make sure you use GPU as a hardware accelerator and display some info about the device\n",
        "Keep in mind that you will need at least 10 GB of GPU memory.\n",
        "You can get Tesla P100 if you're lucky :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQDFTG-tKshm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT4WcWAzdhEO",
        "colab_type": "text"
      },
      "source": [
        "## Clone the repository with the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUJW6VIQJBtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hubertsiuzdak/voice-conversion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yabafha1wY2y",
        "colab_type": "text"
      },
      "source": [
        "## Get the data\n",
        "You will need at least two voices or whatever audio files you want to convert. You can use your own data and then create list of the files as shown below. For the purposes of this demo, we gonna download some .wav files from [CMU_ARCTIC speech synthesis databases.](http://www.festvox.org/cmu_arctic/) \n",
        "BDL represents male voice, SLT - female."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2ZlZ7_ZAeUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_bdl_arctic-0.95-release.zip\n",
        "!unzip -qj cmu_us_bdl_arctic-0.95-release.zip 'cmu_us_bdl_arctic/wav/*' -d bdl_wav_files\n",
        "!wget http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_slt_arctic-0.95-release.zip\n",
        "!unzip -qj cmu_us_slt_arctic-0.95-release.zip 'cmu_us_slt_arctic/wav/*' -d slt_wav_files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T96LUAnvSUU3",
        "colab_type": "text"
      },
      "source": [
        "## Create lists of training files\n",
        "These files will be used to create Data Loaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om5ujmGrJkKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/bdl_wav_files/*.wav | sort -R > /content/voice-conversion/train_files_0.txt\n",
        "!ls /content/slt_wav_files/*.wav | sort -R > /content/voice-conversion/train_files_1.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOYxjTeKdyFx",
        "colab_type": "text"
      },
      "source": [
        "## Edit and save config file. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Note: \n",
        "\n",
        "*   Leave \"checkpoint_path\" empty if you want to train from the scratch.\n",
        "*   Consinder mounting your Google Drive and make it \"output_directory\" so that you won't lose your checkpoints if Colab disconnects.\n",
        "*   Start the training with alpha set to 0. Once discriminator starts to recognize speakers (domain loss gets close to 0) you can increase alpha parameter. Discriminator then becomes adversarial (it tries to maximize classification loss, resulting in speaker-invariant features).\n",
        "*   Setting alpha too high can make the model not converging. On the other hand - too low alpha may result in identity function. Simply put, there would be no conversion.\n",
        "*   Setting alpha to 0.001 after a few thousand of iterations and then gradually increasing seems to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY3ykoqHKQPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile /content/voice-conversion/config.json\n",
        "{\n",
        "    \"train_config\": {\n",
        "        \"output_directory\": \"checkpoints\",\n",
        "        \"epochs\": 1000,\n",
        "        \"learning_rate\": 0.003,\n",
        "        \"alpha\": 0,\n",
        "        \"iters_per_checkpoint\": 1000,\n",
        "        \"num_workers\": 4,\n",
        "        \"batch_size\": 8,\n",
        "        \"pin_memory\": \"True\",\n",
        "        \"seed\": 1234,\n",
        "        \"checkpoint_path\": \"\"\n",
        "    },\n",
        "\n",
        "    \"data_config\": {\n",
        "        \"segment_length\": 16000,\n",
        "        \"mu_quantization\": 256,\n",
        "        \"sampling_rate\": 16000\n",
        "    },\n",
        "\n",
        "    \"model_config\": {\n",
        "        \"n_speakers\": 2,\n",
        "        \"n_in_channels\": 256,\n",
        "        \"n_layers\": 16,\n",
        "        \"max_dilation\": 128,\n",
        "        \"n_residual_channels\": 64,\n",
        "        \"n_skip_channels\": 256,\n",
        "        \"n_out_channels\": 256,\n",
        "        \"n_cond_channels\": 64,\n",
        "        \"upsamp_window\": 1050,\n",
        "        \"upsamp_stride\": 200\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4YVTLtRk-qS",
        "colab_type": "text"
      },
      "source": [
        "## Run the training script\n",
        "Output gets audible after 10-20 thousands of iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xt4mBdOKyJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/voice-conversion/\n",
        "!python train.py -c config.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIYbj2H5lDlJ",
        "colab_type": "text"
      },
      "source": [
        "## Build nv-wavenet and C-wrapper for the inference\n",
        "See the [Nvidia repository](https://github.com/NVIDIA/nv-wavenet) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL2xATJ4dAVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!make\n",
        "!python build.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvs_dXsllInx",
        "colab_type": "text"
      },
      "source": [
        "## Create the list of audio files that you want to convert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9N4k60HdGbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat train_files_0.txt | head -10 > inference.txt\n",
        "!mkdir speaker_0 speaker_1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfkfXJqalSH1",
        "colab_type": "text"
      },
      "source": [
        "## Run the inference sript\n",
        "\n",
        "*   `-f` list of files\n",
        "*   `-c` path to the checkpoint\n",
        "*   `-o` output folder\n",
        "*   `-id` id of the decoder to use (target voice)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fU9FNH5dXGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python inference.py -f inference.txt -c /content/drive/My\\ Drive/vc/wavenet_17000 -o speaker_1 -id 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}